import AVFoundation
import UIKit
import SwiftUI

// MARK: - OCR ç›¸æœºç®¡ç†å™¨
final class OCRCameraManager: NSObject, ObservableObject {
    let session = AVCaptureSession()
    private let sessionQueue = DispatchQueue(label: "ocr.camera.session")
    private let photoOutput = AVCapturePhotoOutput()
    
    @Published var isSessionActive = false
    @Published var flashMode: AVCaptureDevice.FlashMode = .off
    
    private var currentDevice: AVCaptureDevice?
    private var photoCaptureCompletion: ((UIImage?) -> Void)?
    
    override init() {
        super.init()
        configureSession()
    }
    
    // MARK: - Session Control
    func startSession() {
        sessionQueue.async { [weak self] in
            guard let self = self else { return }
            if !self.session.isRunning {
                self.session.startRunning()
                DispatchQueue.main.async {
                    self.isSessionActive = true
                }
                print("ðŸ“¸ OCRç›¸æœºä¼šè¯å·²å¯åŠ¨")
            }
        }
    }
    
    func stopSession() {
        sessionQueue.async { [weak self] in
            guard let self = self else { return }
            if self.session.isRunning {
                self.session.stopRunning()
                DispatchQueue.main.async {
                    self.isSessionActive = false
                }
                print("ðŸ“¸ OCRç›¸æœºä¼šè¯å·²åœæ­¢")
            }
        }
    }
    
    // MARK: - Photo Capture
    func takePhoto(completion: @escaping (UIImage?) -> Void) {
        photoCaptureCompletion = completion
        
        let settings = AVCapturePhotoSettings()
        
        // è®¾ç½®é—ªå…‰ç¯æ¨¡å¼
        if flashMode == .on {
            if photoOutput.supportedFlashModes.contains(.on) {
                settings.flashMode = .on
            }
        } else {
            settings.flashMode = .off
        }
        
        photoOutput.capturePhoto(with: settings, delegate: self)
        print("ðŸ“¸ å¼€å§‹æ‹ç…§ï¼Œé—ªå…‰ç¯: \(flashMode == .on ? "å¼€" : "å…³")")
    }
    
    // MARK: - Flash Control
    func setFlashMode(_ mode: AVCaptureDevice.FlashMode) {
        flashMode = mode
        
        // å¦‚æžœéœ€è¦æ‰‹ç”µç­’å¸¸äº®æ•ˆæžœ
        if mode == .on {
            sessionQueue.async { [weak self] in
                guard let device = self?.currentDevice,
                      device.hasTorch,
                      device.isTorchAvailable else { return }
                
                do {
                    try device.lockForConfiguration()
                    try device.setTorchModeOn(level: 1.0)
                    device.unlockForConfiguration()
                    print("ðŸ“¸ æ‰‹ç”µç­’å·²æ‰“å¼€")
                } catch {
                    print("ðŸ“¸ æ— æ³•æ‰“å¼€æ‰‹ç”µç­’: \(error)")
                }
            }
        } else {
            sessionQueue.async { [weak self] in
                guard let device = self?.currentDevice,
                      device.hasTorch else { return }
                
                do {
                    try device.lockForConfiguration()
                    device.torchMode = .off
                    device.unlockForConfiguration()
                    print("ðŸ“¸ æ‰‹ç”µç­’å·²å…³é—­")
                } catch {
                    print("ðŸ“¸ æ— æ³•å…³é—­æ‰‹ç”µç­’: \(error)")
                }
            }
        }
    }
    
    // MARK: - Camera Switch
    func switchCamera() {
        sessionQueue.async { [weak self] in
            guard let self = self else { return }
            
            self.session.beginConfiguration()
            
            // ç§»é™¤å½“å‰è¾“å…¥
            if let currentInput = self.session.inputs.first as? AVCaptureDeviceInput {
                self.session.removeInput(currentInput)
                
                // åˆ‡æ¢åˆ°å¦ä¸€ä¸ªæ‘„åƒå¤´
                let newPosition: AVCaptureDevice.Position = currentInput.device.position == .back ? .front : .back
                
                guard let newDevice = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: newPosition),
                      let newInput = try? AVCaptureDeviceInput(device: newDevice),
                      self.session.canAddInput(newInput) else {
                    self.session.addInput(currentInput)
                    self.session.commitConfiguration()
                    return
                }
                
                self.session.addInput(newInput)
                self.currentDevice = newDevice
            }
            
            self.session.commitConfiguration()
            print("ðŸ“¸ æ‘„åƒå¤´å·²åˆ‡æ¢")
        }
    }
    
    // MARK: - Private Configuration
    private func configureSession() {
        sessionQueue.async { [weak self] in
            guard let self = self else { return }
            
            self.session.beginConfiguration()
            self.session.sessionPreset = .photo
            
            // é»˜è®¤ä½¿ç”¨åŽç½®æ‘„åƒå¤´
            guard let device = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back),
                  let input = try? AVCaptureDeviceInput(device: device),
                  self.session.canAddInput(input) else {
                self.session.commitConfiguration()
                print("ðŸ“¸ æ— æ³•é…ç½®OCRç›¸æœºè¾“å…¥")
                return
            }
            
            self.session.addInput(input)
            self.currentDevice = device
            
            if self.session.canAddOutput(self.photoOutput) {
                self.session.addOutput(self.photoOutput)
            }
            
            self.session.commitConfiguration()
            print("ðŸ“¸ OCRç›¸æœºé…ç½®å®Œæˆ")
        }
    }
}

// MARK: - AVCapturePhotoCaptureDelegate
extension OCRCameraManager: AVCapturePhotoCaptureDelegate {
    func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {
        if let error = error {
            print("ðŸ“¸ æ‹ç…§å¤±è´¥: \(error)")
            photoCaptureCompletion?(nil)
            return
        }
        
        guard let imageData = photo.fileDataRepresentation(),
              let image = UIImage(data: imageData) else {
            print("ðŸ“¸ æ— æ³•èŽ·å–å›¾ç‰‡æ•°æ®")
            photoCaptureCompletion?(nil)
            return
        }
        
        print("ðŸ“¸ æ‹ç…§æˆåŠŸ")
        photoCaptureCompletion?(image)
    }
}

// MARK: - OCR ç›¸æœºé¢„è§ˆè§†å›¾
struct OCRCameraPreviewView: UIViewRepresentable {
    let session: AVCaptureSession

    func makeUIView(context: Context) -> OCRCameraPreviewUIView {
        let view = OCRCameraPreviewUIView()
        view.session = session
        return view
    }

    func updateUIView(_ uiView: OCRCameraPreviewUIView, context: Context) {}
}

// MARK: - OCR ç›¸æœºé¢„è§ˆ UIView
class OCRCameraPreviewUIView: UIView {
    var session: AVCaptureSession? {
        didSet {
            guard let session = session else { return }
            previewLayer.session = session
        }
    }

    override class var layerClass: AnyClass {
        AVCaptureVideoPreviewLayer.self
    }

    var previewLayer: AVCaptureVideoPreviewLayer {
        layer as! AVCaptureVideoPreviewLayer
    }

    override init(frame: CGRect) {
        super.init(frame: frame)
        previewLayer.videoGravity = .resizeAspectFill
    }

    required init?(coder: NSCoder) {
        fatalError("init(coder:) has not been implemented")
    }
}

